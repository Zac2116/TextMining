{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #99, avg. train loss: 0.56057\n",
      "Step #199, avg. train loss: 0.18557\n",
      "Step #299, avg. train loss: 0.17945\n",
      "Step #399, avg. train loss: 0.13872\n",
      "Step #499, avg. train loss: 0.13075\n",
      "Step #599, avg. train loss: 0.13193\n",
      "Step #699, avg. train loss: 0.11762\n",
      "Step #799, avg. train loss: 0.14715\n",
      "Step #899, avg. train loss: 0.10053\n",
      "Step #999, avg. train loss: 0.14721\n",
      "Step #1099, avg. train loss: 0.15199\n",
      "Step #1199, avg. train loss: 0.15774\n",
      "Step #1299, avg. train loss: 0.11033\n",
      "Step #1399, avg. train loss: 0.15621\n",
      "Step #1499, avg. train loss: 0.12511\n",
      "Step #1599, avg. train loss: 0.13873\n",
      "Step #1699, avg. train loss: 0.14582\n",
      "Step #1799, avg. train loss: 0.17612\n",
      "Step #1899, avg. train loss: 0.11668\n",
      "Step #1999, avg. train loss: 0.15337\n",
      "Step #2099, avg. train loss: 0.17294\n",
      "Step #2199, avg. train loss: 0.12278\n",
      "Step #2299, avg. train loss: 0.13560\n",
      "Step #2399, avg. train loss: 0.15111\n",
      "Step #2499, avg. train loss: 0.15507\n",
      "Step #2599, avg. train loss: 0.13180\n",
      "Step #2699, avg. train loss: 0.12541\n",
      "Step #2799, avg. train loss: 0.11967\n",
      "Step #2899, avg. train loss: 0.13441\n",
      "Step #2999, avg. train loss: 0.12519\n",
      "Step #3099, avg. train loss: 0.13924\n",
      "Step #3199, avg. train loss: 0.13525\n",
      "Step #3299, avg. train loss: 0.09738\n",
      "Step #3399, avg. train loss: 0.12740\n",
      "Step #3499, avg. train loss: 0.11188\n",
      "Step #3599, avg. train loss: 0.12558\n",
      "Step #3699, avg. train loss: 0.11047\n",
      "Step #3799, avg. train loss: 0.11500\n",
      "Step #3899, avg. train loss: 0.12499\n",
      "Step #3999, avg. train loss: 0.13189\n",
      "Step #4099, avg. train loss: 0.11993\n",
      "Step #4199, avg. train loss: 0.12369\n",
      "Step #4299, avg. train loss: 0.12041\n",
      "Step #4399, avg. train loss: 0.11567\n",
      "Step #4499, avg. train loss: 0.13090\n",
      "Step #4599, avg. train loss: 0.13139\n",
      "Step #4699, avg. train loss: 0.15263\n",
      "Step #4799, avg. train loss: 0.13966\n",
      "Step #4899, avg. train loss: 0.14110\n",
      "Step #4999, avg. train loss: 0.13284\n",
      "Step #5099, avg. train loss: 0.10769\n",
      "Step #5199, avg. train loss: 0.11777\n",
      "Step #5299, avg. train loss: 0.13323\n",
      "Step #5399, avg. train loss: 0.11870\n",
      "Step #5499, avg. train loss: 0.15987\n",
      "Step #5599, avg. train loss: 0.12175\n",
      "Step #5699, avg. train loss: 0.16635\n",
      "Step #5799, avg. train loss: 0.10715\n",
      "Step #5899, avg. train loss: 0.13363\n",
      "Step #5999, avg. train loss: 0.12946\n",
      "Step #6099, avg. train loss: 0.14553\n",
      "Step #6199, avg. train loss: 0.13489\n",
      "Step #6299, avg. train loss: 0.15128\n",
      "Step #6399, avg. train loss: 0.13928\n",
      "Step #6499, avg. train loss: 0.11045\n",
      "Step #6599, avg. train loss: 0.14161\n",
      "Step #6699, avg. train loss: 0.10421\n",
      "Step #6799, avg. train loss: 0.12570\n",
      "Step #6899, avg. train loss: 0.14301\n",
      "Step #6999, avg. train loss: 0.12976\n",
      "Step #7099, avg. train loss: 0.11545\n",
      "Step #7199, avg. train loss: 0.13321\n",
      "Step #7299, avg. train loss: 0.12581\n",
      "Step #7399, avg. train loss: 0.16134\n",
      "Step #7499, avg. train loss: 0.11054\n",
      "Step #7599, avg. train loss: 0.15526\n",
      "Step #7699, avg. train loss: 0.14082\n",
      "Step #7799, avg. train loss: 0.11747\n",
      "Step #7899, avg. train loss: 0.12120\n",
      "Step #7999, avg. train loss: 0.11327\n",
      "Step #8099, avg. train loss: 0.13256\n",
      "Step #8199, avg. train loss: 0.12018\n",
      "Step #8299, avg. train loss: 0.11829\n",
      "Step #8399, avg. train loss: 0.15647\n",
      "Step #8499, avg. train loss: 0.13002\n",
      "Step #8599, avg. train loss: 0.12281\n",
      "Step #8699, avg. train loss: 0.13043\n",
      "Step #8799, avg. train loss: 0.16905\n",
      "Step #8899, avg. train loss: 0.14348\n",
      "Step #8999, avg. train loss: 0.13319\n",
      "Step #9099, avg. train loss: 0.13415\n",
      "Step #9199, avg. train loss: 0.12207\n",
      "Step #9299, avg. train loss: 0.11207\n",
      "Step #9399, avg. train loss: 0.17005\n",
      "Step #9499, avg. train loss: 0.09394\n",
      "Step #9599, avg. train loss: 0.13184\n",
      "Step #9699, avg. train loss: 0.10882\n",
      "Step #9799, avg. train loss: 0.12954\n",
      "Step #9899, avg. train loss: 0.14231\n",
      "Step #9999, avg. train loss: 0.13548\n",
      "Step #10099, avg. train loss: 0.12452\n",
      "Step #10199, avg. train loss: 0.14833\n",
      "Step #10299, avg. train loss: 0.13390\n",
      "Step #10399, avg. train loss: 0.13760\n",
      "Step #10499, avg. train loss: 0.16422\n",
      "Step #10599, avg. train loss: 0.12261\n",
      "Step #10699, avg. train loss: 0.13024\n",
      "Step #10799, avg. train loss: 0.10711\n",
      "Step #10899, avg. train loss: 0.10836\n",
      "Step #10999, avg. train loss: 0.12328\n",
      "Step #11099, avg. train loss: 0.12894\n",
      "Step #11199, avg. train loss: 0.12032\n",
      "Step #11299, avg. train loss: 0.14478\n",
      "Step #11399, avg. train loss: 0.14420\n",
      "Step #11499, avg. train loss: 0.13684\n",
      "Step #11599, avg. train loss: 0.12072\n",
      "Step #11699, avg. train loss: 0.10746\n",
      "Step #11799, avg. train loss: 0.13717\n",
      "Step #11899, avg. train loss: 0.16342\n",
      "Step #11999, avg. train loss: 0.13484\n",
      "Step #12099, avg. train loss: 0.11842\n",
      "Step #12199, avg. train loss: 0.08586\n",
      "Step #12299, avg. train loss: 0.12110\n",
      "Step #12399, avg. train loss: 0.11942\n",
      "Step #12499, avg. train loss: 0.13691\n",
      "Step #12599, avg. train loss: 0.13950\n",
      "Step #12699, avg. train loss: 0.12201\n",
      "Step #12799, avg. train loss: 0.12534\n",
      "Step #12899, avg. train loss: 0.15777\n",
      "Step #12999, avg. train loss: 0.10667\n",
      "Step #13099, avg. train loss: 0.14337\n",
      "Step #13199, avg. train loss: 0.11519\n",
      "Step #13299, avg. train loss: 0.13183\n",
      "Step #13399, avg. train loss: 0.10650\n",
      "Step #13499, avg. train loss: 0.12118\n",
      "Step #13599, avg. train loss: 0.11677\n",
      "Step #13699, avg. train loss: 0.14712\n",
      "Step #13799, avg. train loss: 0.13074\n",
      "Step #13899, avg. train loss: 0.16121\n",
      "Step #13999, avg. train loss: 0.12741\n",
      "Step #14099, avg. train loss: 0.13603\n",
      "Step #14199, avg. train loss: 0.14208\n",
      "Step #14299, avg. train loss: 0.11948\n",
      "Step #14399, avg. train loss: 0.12540\n",
      "Step #14499, avg. train loss: 0.13207\n",
      "Step #14599, avg. train loss: 0.14666\n",
      "Step #14699, avg. train loss: 0.13785\n",
      "Step #14799, avg. train loss: 0.10859\n",
      "Step #14899, avg. train loss: 0.13210\n",
      "Step #14999, avg. train loss: 0.11987\n",
      "Step #15099, avg. train loss: 0.14260\n",
      "Step #15199, avg. train loss: 0.13558\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.contrib.learn as skflow\n",
    "import tensorflow.contrib.learn as skflow\n",
    "from sklearn import datasets, metrics\n",
    "from sknn.mlp import Classifier, Layer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"~/Desktop/TextMining/data/features_tfidf_d_train.csv\")\n",
    "data[0:2]\n",
    "\n",
    "import random\n",
    "rows = random.sample(data.index, 25000)\n",
    "train_data = data.ix[rows]\n",
    "test_data = data.drop(rows)\n",
    "\n",
    "y_train = train_data[\"relevance\"]\n",
    "x_train = train_data.drop(['relevance','id'],1)\n",
    "\n",
    "y_test = test_data[\"relevance\"]\n",
    "x_test = test_data.drop(['relevance','id'],1)\n",
    "\n",
    "y_clean = data[\"relevance\"]\n",
    "x_clean = data.drop(['relevance','id'],1)\n",
    "\n",
    "data = pd.read_csv(\"~/Desktop/TextMining/data/features_tfidf_d_train.csv\")\n",
    "\n",
    "\n",
    "regressor = skflow.TensorFlowDNNRegressor(hidden_units=[100,100,100,100],steps=200000, learning_rate=0.1, batch_size=1) #rmse = 0.497\n",
    "\n",
    "regressor = skflow.TensorFlowDNNRegressor(hidden_units=[50,50,50,50,50,50,50,50],steps=200000, learning_rate=0.1, batch_size=1) #rmse = 0.497\n",
    "\n",
    "\n",
    "regressor.fit(x_train, y_train)\n",
    "\n",
    "y_hat = regressor.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=np.array(y_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(y_hat,y))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
